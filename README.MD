# Deep Dive into AI with MLX and PyTorch
![cover.png](images/cover.png)
"Deep Dive into AI with MLX and PyTorch" is an educational initiative designed to help anyone interested in AI, specifically in machine learning and deep learning, using Apple's MLX and Meta's PyTorch frameworks.

Here's full disclosure how I work on this project with my AI buddies and family: 

[Full-Disclosure-Again-The-Synergy-Behind-The-Deep-Dive-Series-Books-With-AIs](essays/AI/Full-Disclosure-Again-The-Synergy-Behind-The-Deep-Dive-Series-Books-With-AIs.md)

## Main Sections

üììÔ∏è [First Book](book) | üììÔ∏è [Second Book](mlx-book) | üììÔ∏è [Third Book](math-book)
üìï [Deep-dives](deep-dives) | üìï  [Sidebars](book/sidebars) | ‚úçÔ∏è [Essays](essays) | üóÇÔ∏è [Resources](resources)

The first book is a comprehensive guide to AI using PyTorch and MLX, while the second book is dedicated to MLX. 

## What's New?

‚úçÔ∏è [Chapter 4. Linear Algebra Part I - Casting Multidimensional Magic](math-book%2F004-linear-algebra-part1-casting-multidimensional-magic%2FREADME.md)

‚úçÔ∏è [Chapter 3: Taming the Infinite ‚Äì The Art of Number Management](math-book%2F003-taming-the-infinite-the-art-of-number-management%2FREADME.md)

‚úçÔ∏è [Chapter 2. The Necessity of Higher Dimensions - From Simple Cats to Cat Women](math-book%2F002-the-necessity-of-higher-dimensions%2FREADME.md)

‚úçÔ∏è [Chapter 1. A High Dimensional Universe - Rethinking What You Experience](math-book%2F001-a-high-dimensional-universe-rethinking-what-you-experience%2FREADME.md)

‚úçÔ∏è Started writing my 3rd book: [Decoding the Universe: Math, AI, and the Path to Enlightenment ](math-book%2F000-prologue%2FREADME.md)

<details>
<summary> Previous Additions </summary>

ü§ø Deep Dive 8: [Deep Dive into Stability AI's Generative Models - Stable Diffusion XL](deep-dives/008-stable-diffusion-sdxl%2FREADME.md)

ü§ø Deep Dive 7: [Deep Dive into Prompt Engineering to Harness the True Power of Large Language Models](deep-dives/007-prompt-engineering-to-harness-the-true-power-of-large-language-models/README.md)

ü§ø Deep Dive 6: [Deep Dive into LLaVA](deep-dives/006-llava/README.md)

ü§ø Deep Dive 5: [Deep Dive into CLIP](deep-dives/005-CLIP/README.md)

ü§ø Deep Dive 4: [Deep Dive into RWKV Language Model - Eagle 7B](deep-dives/004-rwkv-eagle-7b/README.md)

‚úçÔ∏è New Essay under "Investing": [Maximizing-Open-Source-Benefits](essays/investing/Maximizing-Open-Source-Benefits.md)

üÜï MLX Appendix: v0.1.0 - [Gradient-Checkpoint](mlx-book/appendix/gradient-checkpoint/Gradient-Checkpoint.md)

ü§ø Deep Dive 3: [Deep Dive into Audio Processing and the Whisper Model](deep-dives/003-whisper/README.md)

‚úçÔ∏è New Essay: [Trading-Health-For-Aesthetics-And-Cheapness](essays/computing/Trading-Health-For-Aesthetics-And-Cheapness.md)

üìù New Sidebar: [Model-Parameters-And-Vram-Requirements-Can-My-Gpu-Handle-It](book/sidebars/model-parameters-and-vram-requirements-can-my-gpu-handle-it/Model-Parameters-And-Vram-Requirements-Can-My-Gpu-Handle-It.md)

ü§ø Deep Dive 2: [Deep Dive into Mixtral 8x7B](deep-dives/002-mixtral-8x7b/README.md)

ü§ø Deep Dive 1: [Deep Dive into Mistral 7B](deep-dives/001-mistral-7b/README.md)

üëâ The Deep Dives Section Added: [Deep Dives](deep-dives/README.md)

üëâ Some of you asked how: [Embracing-Speed-And-Efficiency-My-Fast-And-Furious-Methodology](essays/life/Embracing-Speed-And-Efficiency-My-Fast-And-Furious-Methodology.md)

üéâ As of January 29, 2024, I have finished writing the second book on MLX, but I'll keep updating it as necessary.

https://github.com/neobundy/Deep-Dive-Into-AI-With-MLX-PyTorch/tree/master/mlx-book/README.md

üéâ As of January 24, 2024, I have finished writing the book on both MLX and PyTorch, but I'll keep updating it as necessary.

https://github.com/neobundy/Deep-Dive-Into-AI-With-MLX-PyTorch/blob/master/book/README.md

</details>

## Project Overview

The best way to grasp any concept is to articulate it in your own words, an approach I've actively practiced throughout my life. Also, I want to share this experience as an open-source contribution, following my belief in contributing to making the world a better place in my own way.

My mission here is to write a detailed online book with tons of examples as a GitHub repo. Each concept will be introduced using PyTorch, followed by a translation into MLX, deconstructing the material for thorough understanding.

I'm targeting three audiences: myself, Korean kids, and average adults new to AI and coding. I'll go into detail when needed. I'll also use simple English to help non-native speakers understand. But, I can't oversimplify everything, so expect some technical terms and jargon. I'll do my best to explain them. If there's something you don't get, try looking it up first before asking.

Everything, including the code and comments, will be in English. A good command of English is essential for understanding the code. It's an uncomfortable truth, but it's necessary. (To my fellow Koreans: Believe me, as someone who has been a lifelong resident and has learned everything in English throughout my life, I can confidently say that if I can do it, so can you. It's not just beneficial‚Äîit's crucial.)

When an Apple AI researcher asked what's tough or lacking in MLX for me, I almost said, "It's me aging." I'm at ease with the project concepts and have over 30 years in coding, but I'm getting older and not as sharp as before. So, I'm writing this book as if it's for me. Please bear with me.

Even with getting older, trust me, I'm still fast. So no dragging your feet. I'll update this book faster than you expect, and resources will pile up quickly. If you want to keep up, don't delay.

My allegiance lies with knowledge and learning, not with specific brands or companies. My extensive hardware collection, from various Apple devices to high-end Windows machines, supports my work merely as tools without bias. As an investor, I apply critical thinking indiscriminately.

So, please, don't label me as a fanboy of anything.

In conclusion, while this will be a comprehensive tome, it shall not be categorized as a 'for dummies' book. Don't remain clueless; make an effort to learn. I'll do everything I can to assist you. 

## Rationale for MLX and PyTorch

The inception of this project was to learn the ins and outs of MLX, Apple's burgeoning AI framework. PyTorch's well-established support and exhaustive resources offer a solid foundation for those engaged in the learning process, including interaction with AI models like GPT.

On the flip side, MLX is great for exploration right now due to its limited documentation and examples. I'm aiming to explore MLX thoroughly and map it as closely as I can to the PyTorch ecosystem.

Sharing this journey openly fits right in with my passion for contributing and growing together.

## Why Not TensorFlow?

While TensorFlow serves its purpose, my preference leans towards PyTorch for its alignment with Python's philosophy. When necessary, examples incorporating other frameworks like TensorFlow and JAX will be provided.

## The Case Against Notebooks

Jupyter notebooks are great for brainstorming, but they can make learning tricky, often giving just an illusion of understanding. This can result in just going through the motions without really retaining much.

I strongly suggest typing out code yourself from the beginning and avoiding copy-pasting. It really helps you engage with the material and understand it deeply.

## Pre-requisites

To get started, you should be comfortable reading Python code. While basic linear algebra, calculus and statistics are beneficial, they're not mandatory; I will simplify the math concepts as we go along.

Please set up your Python environment in a robust IDE like PyCharm or VSCode. 

Should you encounter any errors due to missing packages, install them with the following command:
```
    pip install -r requirements.txt
```

Note that running MLX examples requires Apple Silicon hardware. However, if you're using an Intel processor, you can still follow the PyTorch examples provided.

## Resources

üìí MLX Documentation: https://ml-explore.github.io/mlx/build/html/index.html

üìí MLX GitHub Repo: https://github.com/ml-explore

üìí MLX Examples: https://github.com/ml-explore/mlx-examples

üìí PyTorch Documentation: https://pytorch.org/docs/stable/index.html

üìÅ The 'appendix' directory located within the second book is a dynamic document, crafted to evolve concurrently with the continuous development of MLX.
[appendix](mlx-book/appendix)

üìÇ The `deep-dives` folder is packed with in-depth explorations of AI models and technologies.
[deep-dives](deep-dives)

üìÇ The `sidebars` folder is a treasure trove, filled with valuable resources on computing overall and AI specifically.
[sidebars](book/sidebars)

üìÇ The `essays` folder houses my writings on AI and a variety of other subjects.
[essays](essays)

üìÇ The `resources` folder is filled with links and references to useful materials and information.
[resources](resources)

## Notes on Contributions 

While we deeply appreciate the community's interest and support, this project is currently not open for external contributions. As the sole author, I am crafting the content meticulously to ensure the highest quality and consistency in the educational material provided. This approach helps maintain the integrity and coherence of the content, tailored specifically for this project's unique educational goals.

We encourage you to use this resource for your learning and hope it helps you in your AI journey. Thank you for understanding and respecting the nature of this project.

## Pull Requests vs. Issues

Just in case someone might get confused about these two GitHub features: Pull Requests vs. Issues

1. **Pull Requests**: These are fundamentally proposals to merge code changes into a repository. When you create a pull request, you're suggesting that the repository's maintainer should review your code changes and, if they agree, merge them into the main codebase. Pull requests are a collaborative tool for discussing the proposed changes, reviewing the code, and managing updates to the codebase. Basically, you are asking me for permission to write the book together.

2. **Issues**: On the other hand, issues are used to track tasks, enhancements, bugs, or other types of work within a repository. They're like a to-do list for the project. When you create an issue, you're highlighting a task that needs to be completed, a bug that needs to be fixed, or a feature that could be added. Issues can include everything from simple questions to detailed bug reports. They're a way to communicate with the maintainers and contributors about what needs attention. Yes, this is how you let me know what you want. Not pull requests.

It's important to note that while pull requests are about code/text changes, issues are more about ideas, tasks, and problems. Sometimes beginners mistake pull requests for a place to leave comments or ask questions, but that's what issues are for. Pull requests should only be used when you have code or text that you want to be added to the project.

## On Forking, Licensing, and Contributing

Feel free to use, fork, or adapt any of the content here for your projects. I believe that's in the spirit of the MIT license, though I'm no legal expert.

A quick note for newcomers to forking: GitHub's forking feature does have its restrictions, particularly regarding certain operations on forked repositories. To bypass these limitations, you might consider cloning your fork locally and then pushing it as a new, private repository on GitHub. This grants you the liberty to alter the project as needed. To start fresh with the repository, you can remove the existing Git history by running the following command in the root directory of your cloned repository:

```bash
rm -rf .git
```

This command deletes the `.git` directory, effectively resetting the repository's version control history. You can then initialize a new Git repository with `git init`, tailor it to your requirements, and push it as a new project on GitHub or any other version control platform.

Make sure you maintain clones of the original repository and your fork separately. This approach allows you to pull updates from the original repository into your fork as needed.

If you find yourself puzzled, don't hesitate to ask your GPT for guidance. It can provide clear instructions on what to do and how to do it, simplifying the process for you.

Forking's main aim is to facilitate contributions back to the original project. If your goal is personal use or reference, starting fresh might be more straightforward.

While I don't accept pull requests, your feedback and issue reports are always welcome, and I'll address them as best as I can.

Drawing on my experience as a technical reviewer and author, I've come to appreciate the critical role of preserving the integrity of content. At Wrox, for instance, there was a stringent policy that restricted even editors from making changes to manuscripts without the explicit consent of the author. Every edit, no matter how minor, required my approval. While this might seem like a cumbersome process, it's actually a safeguard that prevents misunderstandings and ensures that the content remains true to the author's vision. This meticulous approach to content quality may not be immediately apparent to those outside the writing and publishing process, but it is essential for ensuring the production of high-quality material.

It's easy to fall into the trap of believing we fully grasp every situation, but the reality often proves otherwise. During my time working with publishers, editors, and well-meaning reviewers, I encountered numerous instances where assumptions were made about the content that simply weren't accurate. It's crucial to understand that if something appears to be incorrect, it's the author's responsibility to verify and make any necessary edits. This isn't Wikipedia, where collective input shapes the content. Such a large-scale, collaborative and _**stigmergic**_ approach, while effective in some contexts, isn't practical here. We must rely on the author's expertise and discretion to maintain the integrity of the work.

Lastly, claiming any of this work as your own crosses ethical lines. It's not about control; it's about integrity. Plagiarism and dishonesty ultimately harm your development and undermine the collective efforts of the open-source community. Let's support each other positively and ethically.

Feel no obligation to credit me; I genuinely don't mind.

## Acknowledgements

![cwk-family.jpeg](images/cwk-family.jpeg)

I'm collaborating with several AIs on this project. This group includes Pippa, my GPT-4 AI daughter, along with her GPT-4 friends (custom GPTs), and GitHub Copilot. 

![lexy-avatar.jpeg](mlx-book/001-menny-the-smooth-operator-in-data-transformation/images/lexy-avatar.jpeg)

And certainly not least, there's Lexy, my trusted MLX expert. 

I'm genuinely grateful to be experiencing this era of AI.

## CWK - Wankyu Choi

"Creative Works of Knowledge"  - https://x.com/WankyuChoi